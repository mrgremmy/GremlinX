import { type Network, type Script } from '@btc-vision/bitcoin';
import type { IHashCommittedP2WSH } from '../../transaction/interfaces/IConsolidatedTransactionParameters.js';
import type { IP2WSHAddress } from '../../transaction/mineable/IP2WSHAddress.js';
import { Logger } from '@btc-vision/logger';
/**
 * Generates hash-committed P2WSH addresses for the Consolidated Hash-Committed Transaction (CHCT) system.
 *
 * These P2WSH scripts enforce that specific data must be provided in the witness to spend the output.
 * If data is stripped or modified, the transaction fails at Bitcoin consensus level.
 *
 * Witness Script Structure (58 bytes):
 * OP_HASH160 <20-byte-hash> OP_EQUALVERIFY <33-byte-pubkey> OP_CHECKSIG
 *
 * Witness Stack (when spending):
 * [signature, data_chunk, witnessScript]
 */
export declare class HashCommitmentGenerator extends Logger {
    /**
     * Maximum chunk size per Bitcoin P2WSH stack item limit.
     * See policy.h: MAX_STANDARD_P2WSH_STACK_ITEM_SIZE = 80
     */
    static readonly MAX_CHUNK_SIZE: number;
    /**
     * Maximum stack items per P2WSH input.
     * See policy.h: MAX_STANDARD_P2WSH_STACK_ITEMS = 100
     */
    static readonly MAX_STACK_ITEMS: number;
    /**
     * Maximum total witness size (serialized).
     * See policy.cpp: GetSerializeSize(tx.vin[i].scriptWitness.stack) > g_script_size_policy_limit
     * Default: 1650 bytes
     */
    static readonly MAX_WITNESS_SIZE: number;
    /** Maximum weight per standard transaction */
    static readonly MAX_STANDARD_WEIGHT: number;
    /** Minimum satoshis per output (dust limit) */
    static readonly MIN_OUTPUT_VALUE: bigint;
    /**
     * Bytes per hash commitment in witness script.
     * OP_HASH160 (1) + push (1) + hash (20) + OP_EQUALVERIFY (1) = 23 bytes
     */
    private static readonly BYTES_PER_COMMITMENT;
    /**
     * Fixed overhead in witness serialization:
     * - Stack item count: 1 byte
     * - Signature: 73 bytes (72 + 1 length prefix)
     * - Script length prefix: 3 bytes (varInt for sizes 253-65535)
     * - Script base (pubkey + checksig): 35 bytes
     */
    private static readonly WITNESS_FIXED_OVERHEAD;
    /**
     * Per-chunk overhead in witness:
     * - Data: 81 bytes (80 + 1 length prefix)
     * - Script commitment: 23 bytes
     * Total: 104 bytes per chunk
     */
    private static readonly WITNESS_PER_CHUNK_OVERHEAD;
    /**
     * Maximum data chunks per P2WSH output.
     * Limited by total witness size: (1650 - 112) / 104 = 14 chunks
     */
    static readonly MAX_CHUNKS_PER_OUTPUT: number;
    /** Base weight per input (non-witness): 41 bytes * 4 = 164 */
    private static readonly INPUT_BASE_WEIGHT;
    /**
     * Witness weight per input with max chunks:
     * Total witness size is ~1566 bytes (under 1650 limit)
     * Witness bytes count as 1 weight unit each.
     */
    private static readonly INPUT_WITNESS_WEIGHT_MAX;
    /** Total weight per input (with max chunks) */
    static readonly WEIGHT_PER_INPUT: number;
    readonly logColor: string;
    private readonly publicKey;
    private readonly network;
    constructor(publicKey: Uint8Array, network?: Network);
    /**
     * Calculate the maximum number of inputs per standard reveal transaction.
     *
     * Standard tx weight limit: 400,000
     * With max chunks per input (~10,385 weight), only ~38 inputs fit
     *
     * @returns Maximum inputs per reveal tx (~38 with max chunks)
     */
    static calculateMaxInputsPerTx(): number;
    /**
     * Calculate maximum data per standard reveal transaction.
     *
     * @returns Maximum data in bytes (~300KB with batched chunks at 70 chunks/output)
     */
    static calculateMaxDataPerTx(): number;
    /**
     * Estimate the number of P2WSH outputs needed for a given data size.
     *
     * @param dataSize Data size in bytes
     * @returns Number of P2WSH outputs needed
     */
    static estimateOutputCount(dataSize: number): number;
    /**
     * Estimate the number of 80-byte chunks for a given data size.
     *
     * @param dataSize Data size in bytes
     * @returns Number of 80-byte chunks needed
     */
    static estimateChunkCount(dataSize: number): number;
    /**
     * Validate that a witness script is a valid multi-hash committed script.
     *
     * Script structure: (OP_HASH160 <hash> OP_EQUALVERIFY)+ <pubkey> OP_CHECKSIG
     *
     * @param witnessScript The witness script to validate
     * @returns true if valid hash-committed script
     */
    static validateHashCommittedScript(witnessScript: Uint8Array): boolean;
    /**
     * Extract all data hashes from a hash-committed witness script.
     *
     * @param witnessScript The witness script
     * @returns Array of 20-byte data hashes (in data order), or null if invalid
     */
    static extractDataHashes(witnessScript: Uint8Array): Uint8Array[] | null;
    /**
     * Extract the public key from a hash-committed witness script.
     *
     * @param witnessScript The witness script
     * @returns The 33-byte public key, or null if invalid script
     */
    static extractPublicKey(witnessScript: Uint8Array): Uint8Array | null;
    /**
     * Verify that data chunks match their committed hashes.
     *
     * @param dataChunks Array of data chunks (in order)
     * @param witnessScript The witness script containing the hash commitments
     * @returns true if all chunks match their commitments
     */
    static verifyChunkCommitments(dataChunks: Uint8Array[], witnessScript: Uint8Array): boolean;
    /**
     * Estimate fees for a complete CHCT flow (setup + reveal).
     *
     * @param dataSize Data size in bytes (before compression)
     * @param feeRate Fee rate in sat/vB
     * @param compressionRatio Expected compression ratio (default: 0.7)
     * @returns Fee estimates
     */
    static estimateFees(dataSize: number, feeRate: number, compressionRatio?: number): {
        compressedSize: number;
        outputCount: number;
        chunkCount: number;
        setupVBytes: number;
        revealVBytes: number;
        setupFee: bigint;
        revealFee: bigint;
        totalFee: bigint;
        outputsValue: bigint;
        totalCost: bigint;
    };
    /**
     * Calculate the HASH160 of a data chunk.
     * HASH160 = RIPEMD160(SHA256(data))
     */
    hashChunk(data: Uint8Array): Uint8Array;
    /**
     * Generate a hash-committed witness script for multiple data chunks.
     *
     * Script structure (for N chunks):
     * OP_HASH160 <hash_N> OP_EQUALVERIFY
     * OP_HASH160 <hash_N-1> OP_EQUALVERIFY
     * ...
     * OP_HASH160 <hash_1> OP_EQUALVERIFY
     * <pubkey> OP_CHECKSIG
     *
     * Hashes are in reverse order because witness stack is LIFO.
     * Witness stack: [sig, data_1, data_2, ..., data_N, witnessScript]
     * Stack before execution: [sig, data_1, data_2, ..., data_N] (data_N on top)
     *
     * @param dataHashes Array of HASH160 values (in data order, will be reversed in script)
     * @returns The compiled witness script
     */
    generateWitnessScript(dataHashes: Uint8Array[]): Uint8Array;
    /**
     * Generate a P2WSH address from a witness script.
     *
     * @param witnessScript The witness script
     * @returns P2WSH address info
     */
    generateP2WSHAddress(witnessScript: Uint8Array | Script): IP2WSHAddress & {
        scriptPubKey: Uint8Array;
    };
    /**
     * Split data into chunks and generate hash-committed P2WSH outputs.
     *
     * Each output commits to up to 98 data chunks (80 bytes each = 7,840 bytes).
     * This is MUCH more efficient than one output per chunk.
     *
     * @param data The data to chunk and commit
     * @param maxChunkSize Maximum bytes per stack item (default: 80, P2WSH stack item limit)
     * @returns Array of hash-committed P2WSH outputs
     */
    prepareChunks(data: Uint8Array, maxChunkSize?: number): IHashCommittedP2WSH[];
}
//# sourceMappingURL=HashCommitmentGenerator.d.ts.map